{"componentChunkName":"component---src-components-blog-blog-template-js","path":"/blog/get-started-with-aws-s3","result":{"data":{"mdx":{"body":"var _excluded = [\"components\"];\nfunction _extends() { return _extends = Object.assign ? Object.assign.bind() : function (n) { for (var e = 1; e < arguments.length; e++) { var t = arguments[e]; for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]); } return n; }, _extends.apply(null, arguments); }\nfunction _objectWithoutProperties(e, t) { if (null == e) return {}; var o, r, i = _objectWithoutPropertiesLoose(e, t); if (Object.getOwnPropertySymbols) { var n = Object.getOwnPropertySymbols(e); for (r = 0; r < n.length; r++) o = n[r], -1 === t.indexOf(o) && {}.propertyIsEnumerable.call(e, o) && (i[o] = e[o]); } return i; }\nfunction _objectWithoutPropertiesLoose(r, e) { if (null == r) return {}; var t = {}; for (var n in r) if ({}.hasOwnProperty.call(r, n)) { if (-1 !== e.indexOf(n)) continue; t[n] = r[n]; } return t; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"slug\": \"blog/get-started-with-aws-s3\",\n  \"title\": \"Get Started with AWS S3\",\n  \"description\": \"Learn what is S3, the core parts of S3, and get to practice, by implementing the AWS SDK for Node.js ðŸ’» Finally, we'll provide a cheat sheet on AWS S3 CMD Commands.\",\n  \"tags\": [\"AWS\", \"Cloud Computing\", \"Cloud Services\", \"Storage\", \"S3\"],\n  \"featureImage\": \"./assets/get-started-with-aws-s3/get_started_with_S3_featureImg.png\",\n  \"author\": \"albiona\",\n  \"date\": \"2021-01-25T00:00:00.000Z\"\n};\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\nvar ExternalLink = makeShortcode(\"ExternalLink\");\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"When developing your web application, you must think of a place where to store your data, how to back up them, types of data you want to store, such as images, music, and videos, application hosting, data archiving, disaster recoveries. AWS Simple Storage Service (S3) provides you the solutions for these cases. S3 is one of the core services of AWS cloud infrastructure. It's \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"object storage\"), \" that acts like a regular file system on your personal computer. S3 scales infinitely, with no limit on the amount of data you store.\"), mdx(\"p\", null, \"In this tutorial, we'll get to learn how to use the AWS S3. First, learn what is S3, the core parts of S3 that are the Buckets, Access Point, and Objects. Then we'll get to the practice, by implementing the AWS SDK for Node.js \\uD83D\\uDCBB Finally, we'll provide a cheat sheet on AWS S3 CMD Commands.\"), mdx(\"hr\", null), mdx(\"p\", null, \"Amazon Web Services (AWS) provides multiple types of cloud computing services, one of them is the AWS Storage Service. There are different storage services, such as Simple Storage Service (S3), AWS Elastic File System (EFS), & Elastic Block Store (EBS).\\nFor this tutorial, we'll be focusing on the S3 service. S3 is one of the most favorite cloud computing services among all the other services, based on \", mdx(ExternalLink, {\n    href: \"https://twitter.com/acloudguru/status/1240722699493801987\",\n    mdxType: \"ExternalLink\"\n  }, \"this poll\"), \" by \", mdx(ExternalLink, {\n    href: \"http://acloud.guru\",\n    mdxType: \"ExternalLink\"\n  }, \"acloud.guru\"), \" on Twitter.\"), mdx(\"hr\", null), mdx(\"h2\", {\n    \"id\": \"what-is-s3\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"What Is S3?\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#what-is-s3\",\n    \"aria-label\": \"what is s3 permalink\",\n    \"className\": \"heading-link-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"fill\": \"none\",\n    \"viewBox\": \"0 0 24 24\",\n    \"stroke\": \"currentColor\"\n  }, \"\\n                              \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"strokeLineCap\": \"round\",\n    \"strokeLineJoin\": \"round\",\n    \"strokeWidth\": \"2\",\n    \"d\": \"M7 20l4-16m2 16l4-16M6 9h14M4 15h14\"\n  }), \"\\n                            \"))), mdx(\"p\", null, \"You can use S3 to host your static websites, delivering HTML, JavaScript, images, videos, and other files to your website visitors - that doesn't contain server-side code such as Node.js or PHP. Using S3, you can easily deploy your applications in just two to three clicks via the user interface. S3 provides a simple web services interface you can use to store and retrieve any amount of data from anywhere on the web.\"), mdx(\"p\", null, \"We'll now go through the core concepts of S3, such as \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"buckets\"), \", \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"access points\"), \", and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"objects\"), \".\"), mdx(\"h3\", {\n    \"id\": \"buckets\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Buckets\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#buckets\",\n    \"aria-label\": \"buckets permalink\",\n    \"className\": \"heading-link-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"fill\": \"none\",\n    \"viewBox\": \"0 0 24 24\",\n    \"stroke\": \"currentColor\"\n  }, \"\\n                              \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"strokeLineCap\": \"round\",\n    \"strokeLineJoin\": \"round\",\n    \"strokeWidth\": \"2\",\n    \"d\": \"M7 20l4-16m2 16l4-16M6 9h14M4 15h14\"\n  }), \"\\n                            \"))), mdx(\"p\", null, \"To upload your data to S3, you must create an S3 bucket in one of the AWS Regions, within one bucket you can upload many objects to the bucket. For implementation, buckets and objects are resources, and S3 provides \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"APIs\"), \" for you to manage them. There are different methods you can use to create buckets such as.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Amazon S3 Console\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Follow the guides \", mdx(ExternalLink, {\n    href: \"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html\",\n    mdxType: \"ExternalLink\"\n  }, \"here\"), \" to create your first bucket with the S3 console.\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"REST API\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"To create buckets using REST API, you must authenticate your requests \\u2014 follow the \", mdx(ExternalLink, {\n    href: \"https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateBucket.html\",\n    mdxType: \"ExternalLink\"\n  }, \"PUT Bucket\"), \" in the S3 API reference. But it's recommended to use the AWS Management Console or AWS SDKs instead.\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"AWS SDK\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"To create buckets with the SDK, you first have to create a \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"client\"), \" and then use the client to send \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"a request\"), \" to \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"create a bucket\"), \". Note: When creating the client and the bucket, use the same region. Here is a dominant \", mdx(ExternalLink, {\n    href: \"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/s3-example-creating-buckets.html\",\n    mdxType: \"ExternalLink\"\n  }, \"source\"), \" on creating and using AWS S3 Buckets.\")))), mdx(\"h3\", {\n    \"id\": \"access-points\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Access Points\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#access-points\",\n    \"aria-label\": \"access points permalink\",\n    \"className\": \"heading-link-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"fill\": \"none\",\n    \"viewBox\": \"0 0 24 24\",\n    \"stroke\": \"currentColor\"\n  }, \"\\n                              \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"strokeLineCap\": \"round\",\n    \"strokeLineJoin\": \"round\",\n    \"strokeWidth\": \"2\",\n    \"d\": \"M7 20l4-16m2 16l4-16M6 9h14M4 15h14\"\n  }), \"\\n                            \"))), mdx(\"p\", null, \"To access the data that you store on S3, you need the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"S3 Access Point\"), \". These are \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"endpoints\"), \" that are attached to buckets that you used to perform S3 object operations.\"), mdx(\"p\", null, \"Each access point has distinct permissions and network controls S3 applies for any request that is made through the access point. Access points are used to perform operations on \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"objects\"), \", but \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"not\"), \" on \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"buckets\"), \". Go through this \", mdx(ExternalLink, {\n    href: \"https://docs.aws.amazon.com/AmazonS3/latest/dev/access-points.html\",\n    mdxType: \"ExternalLink\"\n  }, \"source\"), \" to learn how to manage data access with S3 access points.\"), mdx(\"h3\", {\n    \"id\": \"objects\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Objects\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#objects\",\n    \"aria-label\": \"objects permalink\",\n    \"className\": \"heading-link-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"fill\": \"none\",\n    \"viewBox\": \"0 0 24 24\",\n    \"stroke\": \"currentColor\"\n  }, \"\\n                              \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"strokeLineCap\": \"round\",\n    \"strokeLineJoin\": \"round\",\n    \"strokeWidth\": \"2\",\n    \"d\": \"M7 20l4-16m2 16l4-16M6 9h14M4 15h14\"\n  }), \"\\n                            \"))), mdx(\"p\", null, \"We mentioned that AWS S3 is object storage. Each AWS S3 object has data, a key, and metadata. The object key (or key name) uniquely identifies the object in a bucket. Object metadata is a set of name-value pairs.\"), mdx(\"p\", null, \"You can store objects in one or more buckets, and each object can be up to 5 TB in size. For the real-world solutions, let's say you want to share an image or video stored in AWS S3 bucket on your website, that is possible only if you make the object public or use a pre-signed URL on your website. Follow this \", mdx(ExternalLink, {\n    href: \"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html\",\n    mdxType: \"ExternalLink\"\n  }, \"source\"), \" on how to work with S3 objects.\"), mdx(\"h2\", {\n    \"id\": \"hands-on-s3-with-aws-sdk\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Hands-on S3 With AWS SDK\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#hands-on-s3-with-aws-sdk\",\n    \"aria-label\": \"hands on s3 with aws sdk permalink\",\n    \"className\": \"heading-link-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"fill\": \"none\",\n    \"viewBox\": \"0 0 24 24\",\n    \"stroke\": \"currentColor\"\n  }, \"\\n                              \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"strokeLineCap\": \"round\",\n    \"strokeLineJoin\": \"round\",\n    \"strokeWidth\": \"2\",\n    \"d\": \"M7 20l4-16m2 16l4-16M6 9h14M4 15h14\"\n  }), \"\\n                            \"))), mdx(\"p\", null, \"We'll go with the AWS SDK and Node.js to \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"create\"), \" S3 buckets, \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"uploading\"), \" an object to a specified bucket and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deleting\"), \" that bucket afterward; we'll provide a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"How-To on the S3\"), \" section where you can learn more about different use-cases commands to run on S3.\"), mdx(\"p\", null, \"In order to continue, you must:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Install Node.js, in case you don't have it, follow the \", mdx(ExternalLink, {\n    href: \"https://nodejs.org/en/\",\n    mdxType: \"ExternalLink\"\n  }, \"Node.js website\"), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Set up your user credentials, follow \", mdx(ExternalLink, {\n    href: \"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/loading-node-credentials-shared.html\",\n    mdxType: \"ExternalLink\"\n  }, \"here\"), \" for more information.\")), mdx(\"h3\", {\n    \"id\": \"configuring-the-sdk\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Configuring the SDK\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#configuring-the-sdk\",\n    \"aria-label\": \"configuring the sdk permalink\",\n    \"className\": \"heading-link-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"fill\": \"none\",\n    \"viewBox\": \"0 0 24 24\",\n    \"stroke\": \"currentColor\"\n  }, \"\\n                              \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"strokeLineCap\": \"round\",\n    \"strokeLineJoin\": \"round\",\n    \"strokeWidth\": \"2\",\n    \"d\": \"M7 20l4-16m2 16l4-16M6 9h14M4 15h14\"\n  }), \"\\n                            \"))), mdx(\"p\", null, \"To use the AWS SDK for JavaScript, we must first initiate a node module for our hands-on project.\"), mdx(\"p\", null, \"To do that, first, create a folder named \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"webiny-hands-on-s3\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"cd\"), \" into that folder.\"), mdx(\"p\", null, \"Run the command \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"npm init\"), \" \\u2014 this will ask you to provide the project's name and you can name it as you want, in this case, we'll leave it the same as the folder name with an entry point of the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"index.js\"), \" file.\"), mdx(\"p\", null, \"Inside our folder, we'll create a couple of files, such as.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"createBucket.js\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"upload.js\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"listObjects.js\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"deleteBucket.js\"))), mdx(\"p\", null, \"Before we continue to implement any code, we need to install the AWS SDK package by running this command: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"npm install aws-sdk --save\"), \".\"), mdx(\"p\", null, \"Let's dive in.\"), mdx(\"hr\", null), mdx(\"h3\", {\n    \"id\": \"creating-an-aws-s3-bucket\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Creating an AWS S3 Bucket\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#creating-an-aws-s3-bucket\",\n    \"aria-label\": \"creating an aws s3 bucket permalink\",\n    \"className\": \"heading-link-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"fill\": \"none\",\n    \"viewBox\": \"0 0 24 24\",\n    \"stroke\": \"currentColor\"\n  }, \"\\n                              \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"strokeLineCap\": \"round\",\n    \"strokeLineJoin\": \"round\",\n    \"strokeWidth\": \"2\",\n    \"d\": \"M7 20l4-16m2 16l4-16M6 9h14M4 15h14\"\n  }), \"\\n                            \"))), mdx(\"p\", null, \"In order to use the SDK, we have to configure the SDK package by loading it into our file. Open the createBucket.js file, and start writing the below code in your own file. In the snippet we have comments to explain to you what we're doing:\"), mdx(\"deckgo-highlight-code\", {\n    \"language\": \"tsx\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"// Load the AWS SDK for Node.js\\nvar AWS = require(\\\"aws-sdk\\\");\\n\\n// Set the region\\nAWS.config.update({ region: \\\"us-east-1\\\" });\\n\\n// Create S3 service object\\ns3 = new AWS.S3({ apiVersion: \\\"2006-03-01\\\" });\\n\\n// Create the parameters for calling createBucket -- with this part we'll take the bucket name we'll create\\nvar bucketParams = {\\n  Bucket: process.argv[2],\\n};\\n\\n// Call S3 to create the buckets\\ns3.createBucket(bucketParams, function(err, data) {\\n  err ? console.log(\\\"Error\\\", err) : console.log(\\\"Success\\\", data.Location);\\n});\"), \"\\n        \"), mdx(\"p\", null, \"To create your S3 bucket, with this script, we must run it and give our bucket a name like so: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"node createBucket.js webiny-s3-bucket-testing\"), \".\\nIf it's successful, it will console log the Success message together with the location, which will be the bucket name.\"), mdx(\"h3\", {\n    \"id\": \"uploading-a-file-to-an-aws-s3-bucket\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Uploading a File to an AWS S3 Bucket\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#uploading-a-file-to-an-aws-s3-bucket\",\n    \"aria-label\": \"uploading a file to an aws s3 bucket permalink\",\n    \"className\": \"heading-link-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"fill\": \"none\",\n    \"viewBox\": \"0 0 24 24\",\n    \"stroke\": \"currentColor\"\n  }, \"\\n                              \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"strokeLineCap\": \"round\",\n    \"strokeLineJoin\": \"round\",\n    \"strokeWidth\": \"2\",\n    \"d\": \"M7 20l4-16m2 16l4-16M6 9h14M4 15h14\"\n  }), \"\\n                            \"))), mdx(\"p\", null, \"Open the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"upload.js\"), \" file and let's dive in. I will repeat some parts of the snippets, such as the SDK configuration, and the AWS S3 service object as shown in the above snippet. The additional part is that we have two command-line arguments, the first one will be the bucket name where you'll upload your file, and the second argument will be the file itself.\"), mdx(\"p\", null, \"Let's dive into the code.\"), mdx(\"deckgo-highlight-code\", {\n    \"language\": \"tsx\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"// Load the AWS SDK for Node.js\\nvar AWS = require(\\\"aws-sdk\\\");\\n\\n// Set the region\\nAWS.config.update({ region: \\\"us-east-1\\\" });\\n\\n// Create S3 service object\\ns3 = new AWS.S3({ apiVersion: \\\"2006-03-01\\\" });\\n\\n// Call S3 to retrieve upload file to specified bucket\\nvar uploadParams = { Bucket: process.argv[2], Key: \\\"\\\", Body: \\\"\\\" };\\nvar file = process.argv[3];\\n\\n// Configure the file stream and obtain the upload parameters\\n// The node.js file system module allows you to work (read, create, update, delete, rename files)\\n// with the file system on your computer.\\nvar fs = require(\\\"fs\\\");\\nvar readingFile = fs.createReadStream(file);\\nreadingFile.on(\\\"error\\\", function(err) {\\n  console.log(\\\"File Error\\\", err);\\n});\\n\\nuploadParams.Body = readingFile;\\n// The path module provides utilities for working with file and directory paths.\\n// We can access by using this:\\nvar path = require(\\\"path\\\");\\nuploadParams.Key = path.basename(file);\\n\\n// Call S3 to retrieve upload file to specified bucket\\ns3.upload(uploadParams, function(err, data) {\\n  err ? console.log(\\\"Error\\\", err) : console.log(\\\"Upload Success!\\\", data.Location);\\n});\"), \"\\n        \"), mdx(\"p\", null, \"Now, create an \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"index.txt\"), \" file in your folder, and add some text into it.\"), mdx(\"p\", null, \"Then, run the script by providing two parameters:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The S3 bucket we create in the first snippet \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"webiny-s3-bucket-testing\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The local file you want to upload into that S3 bucket.\")), mdx(\"p\", null, \"The full command \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"node upload.js webiny-s3-bucket-testing index.txt\")), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"800px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/e14f08bc5e76e1d44e8dbbc74aabcd90/d56e1/upload.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"8.5%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAdklEQVQI10WM3Q6CMAyFeRoiU+iYjE2MGGMGIfwGEvT9X+SY9kIuTvqdr00je99w9Quo6EF2kKSmg/EL8nKCrTbkboYuRxTVKs64+WB/7Jij2/ML99jlER9yfP0RF19eUNTgrFuc0jeSLEBRkMlO6QYJdwp//gFp6EN7d1s9XgAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Upload.js file\",\n    \"title\": \"Upload.js file\",\n    \"src\": \"/static/e14f08bc5e76e1d44e8dbbc74aabcd90/5a190/upload.png\",\n    \"srcSet\": [\"/static/e14f08bc5e76e1d44e8dbbc74aabcd90/772e8/upload.png 200w\", \"/static/e14f08bc5e76e1d44e8dbbc74aabcd90/e17e5/upload.png 400w\", \"/static/e14f08bc5e76e1d44e8dbbc74aabcd90/5a190/upload.png 800w\", \"/static/e14f08bc5e76e1d44e8dbbc74aabcd90/d56e1/upload.png 1130w\"],\n    \"sizes\": \"(max-width: 800px) 100vw, 800px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"\\uD83C\\uDF89 You just uploaded a file into your S3 bucket!\"), mdx(\"h3\", {\n    \"id\": \"listing-objects-in-an-aws-s3-bucket\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Listing Objects in an AWS S3 Bucket\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#listing-objects-in-an-aws-s3-bucket\",\n    \"aria-label\": \"listing objects in an aws s3 bucket permalink\",\n    \"className\": \"heading-link-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"fill\": \"none\",\n    \"viewBox\": \"0 0 24 24\",\n    \"stroke\": \"currentColor\"\n  }, \"\\n                              \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"strokeLineCap\": \"round\",\n    \"strokeLineJoin\": \"round\",\n    \"strokeWidth\": \"2\",\n    \"d\": \"M7 20l4-16m2 16l4-16M6 9h14M4 15h14\"\n  }), \"\\n                            \"))), mdx(\"p\", null, \"Now, open the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"listObjects.js\"), \" file where you'll list the content of this bucket. It's again a repetitive task of configuring the SDK and creating the AWS S3 service object. What this script will do, is that we'll provide the bucket name from which we want to read the objects and the result will be a list of objects (files) or a failure message.\"), mdx(\"p\", null, \"Let's dive into the code.\"), mdx(\"deckgo-highlight-code\", {\n    \"language\": \"tsx\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"// Load the AWS SDK for Node.js\\nvar AWS = require(\\\"aws-sdk\\\");\\n\\n// Set the region\\nAWS.config.update({ region: \\\"us-east-1\\\" });\\n\\n// Create S3 service object\\ns3 = new AWS.S3({ apiVersion: \\\"2006-03-01\\\" });\\n\\n// Create the parameters for calling listObjects method\\nvar bucketParams = {\\n  // in here we'll provide the bucket name we created earlier\\n  Bucket: \\\"webiny-s3-bucket-testing\\\",\\n};\\n\\n// Call S3 to obtain a list of the objects in the bucket\\n\\ns3.listObjects(bucketParams, function(err, data) {\\n  err ? console.log(\\\"Error\\\", err) : console.log(\\\"Success\\\", data);\\n});\"), \"\\n        \"), mdx(\"p\", null, \"Now, let's run the script by running this command: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"node listObjects.js\"), \" Check out the result \\uD83D\\uDE04\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"730px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/21068b53f086b61d80b29fac53fd0177/e9beb/listObjects.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"69.5%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABYlAAAWJQFJUiTwAAACRklEQVQ4y3VU207bQBTMjxTs+H5NHOPYa3vjaxJDnDQQEqCo9KUgob71/6Wpdl2HksLDaPasrNlzGw9c/wo+uYYfbWGOFlDMHLIxg25RjqGWQlQTzj1YLOmUo7t7+26g2SVCukeQ7DCJtvDTHezxHDEpQJM5FHP2TrA/Mz4Fux/IRoZpukdED3AvVtCcEpI+wxeJ4EyOIarpu+w+g6glGKopBiww3Br25BKaU0E2M8h2DsmgkMwZBD3BuUIgqDGEnv/BmRJ1Yn3J7CAoMRccB2tYfoOguYeX38BNNry/ljWHYVaw7AVMq4Zh1jCMirM3biGplGvwkntBx79Ckn/repnvEa++g7RPqLevKNpn5O1PFOtnFJsXVNevmO9+oVi/YH37G152A8Ut3koWeYYNQnoH16tB0jnUSQ0jamDEVxxmuoJOGmjTRXdPGujhEvKkhB4sodj5SYaTS4T0gIjuQfIDAnqA6TWw4xYXqwcEm0dY4SVEiUCQCQSJQGRDk2MIjJVu0oN+3KyHrF9sQE6yQ7D4gXF+D8UpMdS7ATEeHnfvYwzYcqpWwdXPpPDv6yHOxSnOh13MX1fibt96ZtCS/wWZWJw/wPVXMIIlvOYOZrqBM/uKUXGNUXkDN9/CpmvOLNZGFRf+MEPFyjFNbvliG94S42gBwhxiZxgalO+kbGW8ZIntqJXxsk/teBRkTiHZPWb1E6bpAUnSYtt29lOtkq/CW7nJsfkfeZwL6k7F7aa7NVS7gGKVkMyK/yRYO462OrXaJxn+AWsnv0+WeMhCAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"listObjects result\",\n    \"title\": \"listObjects result\",\n    \"src\": \"/static/21068b53f086b61d80b29fac53fd0177/e9beb/listObjects.png\",\n    \"srcSet\": [\"/static/21068b53f086b61d80b29fac53fd0177/772e8/listObjects.png 200w\", \"/static/21068b53f086b61d80b29fac53fd0177/e17e5/listObjects.png 400w\", \"/static/21068b53f086b61d80b29fac53fd0177/e9beb/listObjects.png 730w\"],\n    \"sizes\": \"(max-width: 730px) 100vw, 730px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"h3\", {\n    \"id\": \"deleting-an-aws-s3-bucket\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Deleting an AWS S3 Bucket\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#deleting-an-aws-s3-bucket\",\n    \"aria-label\": \"deleting an aws s3 bucket permalink\",\n    \"className\": \"heading-link-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"fill\": \"none\",\n    \"viewBox\": \"0 0 24 24\",\n    \"stroke\": \"currentColor\"\n  }, \"\\n                              \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"strokeLineCap\": \"round\",\n    \"strokeLineJoin\": \"round\",\n    \"strokeWidth\": \"2\",\n    \"d\": \"M7 20l4-16m2 16l4-16M6 9h14M4 15h14\"\n  }), \"\\n                            \"))), mdx(\"p\", null, \"Move to the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"deleteBucket.js\"), \" file, and configure the SDK and create the AWS S3 service object. What you'll use in this script, comparing with the above script, is the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"deleteBucket\"), \" method. But, this case is different, we previously added objects into our bucket, right? We can't delete the AWS S3 buckets if they're not empty. That means you need to delete the objects inside the bucket first, then delete the bucket.\"), mdx(\"p\", null, \"Let's dive in.\"), mdx(\"deckgo-highlight-code\", {\n    \"language\": \"tsx\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"// Load the AWS SDK for Node.js\\nvar AWS = require(\\\"aws-sdk\\\");\\n\\n// Set the region\\nAWS.config.update({ region: \\\"us-east-1\\\" });\\n\\n// Create S3 service object\\ns3 = new AWS.S3({ apiVersion: \\\"2006-03-01\\\" });\\n\\n// Create params for S3.deleteBucket\\nvar bucketParams = {\\n  // here you'll provide the name of the bucket you want to delete\\n  Bucket: \\\"webiny-s3-bucket-testing\\\",\\n};\\n\\n// We'll first empty the bucket\\nasync function emptyS3Bucket(bucket) {\\n  const listParams = {\\n    Bucket: bucket,\\n    // Prefix: dir,\\n  };\\n\\n  const listedObjects = await s3.listObjectsV2(listParams).promise();\\n\\n  if (listedObjects.Contents.length === 0) return;\\n\\n  const deleteParams = {\\n    Bucket: bucket,\\n    Delete: { Objects: [] },\\n  };\\n\\n  listedObjects.Contents.forEach(({ Key }) => {\\n    deleteParams.Delete.Objects.push({ Key });\\n  });\\n\\n  await s3.deleteObjects(deleteParams).promise();\\n\\n  if (listedObjects.IsTruncated) await emptyS3Bucket(bucket);\\n}\\n\\nemptyS3Directory(bucketParams.Bucket);\\n\\n// Call S3 to delete the bucket\\ns3.deleteBucket(bucketParams, function(err, data) {\\n  err ? console.log(\\\"Error\\\", err) : console.log(\\\"Success\\\", data);\\n});\"), \"\\n        \"), mdx(\"h2\", {\n    \"id\": \"how-to-on-s3---cheatsheet\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"inlineCode\", {\n    parentName: \"h2\"\n  }, \"How-to\"), \" on S3 - Cheatsheet\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#how-to-on-s3---cheatsheet\",\n    \"aria-label\": \"how to on s3   cheatsheet permalink\",\n    \"className\": \"heading-link-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"fill\": \"none\",\n    \"viewBox\": \"0 0 24 24\",\n    \"stroke\": \"currentColor\"\n  }, \"\\n                              \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"strokeLineCap\": \"round\",\n    \"strokeLineJoin\": \"round\",\n    \"strokeWidth\": \"2\",\n    \"d\": \"M7 20l4-16m2 16l4-16M6 9h14M4 15h14\"\n  }), \"\\n                            \"))), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Download an entire AWS S3 bucket\"), mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Install the AWS Command Line Tools\"), mdx(\"deckgo-highlight-code\", {\n    parentName: \"li\",\n    \"language\": \"jsx\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"sudo easy_install awscli\\n// or\\nsudo pip install awscli\\n// or\\nbrew install awscli\"), \"\\n        \")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Run these commands:\"), mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"aws s3 sync s3://<source_bucket> <local_destination>\")), mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Example: \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"aws s3 sync s3://mybucket .\"), \"\\nWill download all the objects in\\xA0\", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"mybucket\"), \"\\xA0to the current directory.\\nAnd will output:\")), mdx(\"deckgo-highlight-code\", {\n    parentName: \"li\",\n    \"highlight-lines\": \"undefined\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"download: s3://mybucket/test.txt to test.txt\"), \"\\n        \")))))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Are AWS S3 buckets region specific?\"), mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The user interface shows all your buckets, in all regions. But buckets exist in a specific region and you need to specify that region when you create a bucket.\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"How to Configure SSL for AWS S3 bucket?\"), mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Example: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://s3.amazonaws.com/bucket_name/images/logo.gif\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"a\"\n  }, \"https://s3.amazonaws.com/bucket_name/images/logo.gif\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"If you use a custom domain for your bucket, you can use S3 and CloudFront together with your own SSL certificate (or generate a free one via Amazon Certificate Manager): \", mdx(ExternalLink, {\n    href: \"http://aws.amazon.com/cloudfront/custom-ssl-domains/\",\n    mdxType: \"ExternalLink\"\n  }, \"Amazon CloudFront Custom SSL\")))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Delete AWS S3 buckets\"), mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"aws s3 rb s3://bucket-name\"), mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"By default, the bucket must be empty for the operation to succeed. To remove a bucket that's not empty, you need to include the \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"--force\"), \" option.\\n\", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"aws s3 rb s3://bucket-name --force\")))))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Rename AWS S3 Bucket name\"), mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"There is no rename bucket functionality for S3 because there are technically no folders in S3, so we have to handle every file within the bucket.\")), mdx(\"deckgo-highlight-code\", {\n    parentName: \"li\",\n    \"language\": \"jsx\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"aws s3 mb s3://[new-bucket] // 1. Create a new bucket\\naws s3 sync s3://[old-bucket] s3://[new-bucket] // 2. Copy files over\\naws s3 rb --force s3://[old-bucket] // 3. Delete the old bucket\"), \"\\n        \")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Quick way to list all files in AWS S3 bucket\"), mdx(\"deckgo-highlight-code\", {\n    parentName: \"li\",\n    \"language\": \"jsx\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"aws s3 ls\"), \"\\n        \")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"AWS S3 copy files and folders between two buckets\"), mdx(\"deckgo-highlight-code\", {\n    parentName: \"li\",\n    \"language\": \"jsx\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"aws s3 sync s3://DOC-EXAMPLE-BUCKET-SOURCE s3://DOC-EXAMPLE-BUCKET-TARGET\"), \"\\n        \")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Is it better to have multiple s3 buckets or one bucket with sub folders?\"), mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"By default, you can create up to 100 buckets in each of your AWS accounts. If you need additional buckets, you can increase your bucket limit by submitting a service limit increase. \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html\"\n  }, \"Source\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The total volume of data and number of objects you can store are unlimited. \", mdx(ExternalLink, {\n    href: \"https://aws.amazon.com/s3/faqs/\",\n    mdxType: \"ExternalLink\"\n  }, \"Source\"), \".\")))), mdx(\"hr\", null), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"*\", \"Object Storage \\u2014\"), \" Also known as object-based storage, is a strategy that manages and manipulates data storage as distinct units, called objects. There are three key components of an object \\u2014 \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"the content\"), \" of the object (data stored in the object such as a file or directory), \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"the unique object identifier (ID),\"), \" and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"metadata. It stores t\"), \"he metadata as key-pair values and contains information such as name, size, date, security attributes, content type, and URL. Each object has an access control list (ACL) to configure who \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"may access the object.\")), mdx(\"hr\", null), mdx(\"p\", null, \"Now that you've used AWS SDK for S3, you're able to code the solutions that the AWS S3 Console provides via a few clicks, which is faster but, using the SDK you'll be able to continue developing your applications using the AWS services directly by coding. This is a significant advantage for those interested in building applications using AWS services. In this tutorial, we used the AWS SDK to create buckets, upload data, listing data from the buckets, empty, and afterward deleting buckets via AWS SDK for JavaScript for Node.js.\"), mdx(\"hr\", null), mdx(\"p\", null, \"If you learned something \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"new\"), \" today and are interested to \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"follow up on our blogs\"), \", \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(ExternalLink, {\n    href: \"https://landing.mailerlite.com/webforms/landing/g9f1i1\",\n    mdxType: \"ExternalLink\"\n  }, \"subscribe \")), \" to our newsletter and we'll provide you the best content of the serverless world!\"), mdx(\"hr\", null), mdx(\"p\", null, \"Thanks for reading! My name is \", mdx(ExternalLink, {\n    href: \"https://twitter.com/albionaitoh\",\n    mdxType: \"ExternalLink\"\n  }, \"Albiona\"), \" and I work as a developer relations engineer at \", mdx(ExternalLink, {\n    href: \"https://www.hoola.ai/\",\n    mdxType: \"ExternalLink\"\n  }, \"Hoola AI\"), \". I enjoy learning new tech and building communities around them = ) If you have questions or just want to say hi, reach out to me via \", mdx(ExternalLink, {\n    href: \"https://twitter.com/albionaitoh\",\n    mdxType: \"ExternalLink\"\n  }, \"Twitter\"), \".\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"author":"albiona","slug":"blog/get-started-with-aws-s3","title":"Get Started with AWS S3","description":"Learn what is S3, the core parts of S3, and get to practice, by implementing the AWS SDK for Node.js ðŸ’» Finally, we'll provide a cheat sheet on AWS S3 CMD Commands.","tags":["AWS","Cloud Computing","Cloud Services","Storage","S3"],"date":"January 25, 2021","featureImage":{"publicURL":"/static/5bb496f1ffa55fce8f7a89258870f8d8/get_started_with_S3_featureImg.png","childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADEklEQVQozyXM207aBwDAYV5gyZKKoq3Zltm0SberXuxcbKOIoKJMzBSqaCcS5Q8VOYiCOCglIFRUcOIBRuuhzCk2asuKVuch0xC7dNmyZBfLbvYcv2XZ9wCfyHRVzddX6hEqlDgvN2N8pwmT5QEW4QFTyXX6DR6UukFauh24h6Osbu4R8U0Tiy0xqjITvvYV/g87MF9vxnxdjajv3SbsYgXOKyo877Vhr9Iw7Iwy2GRhSHjIeGAeRbuAqtOKP7jIiDOKS2UhMrGEu6af6FUt7vc13C9Xoq+QIdKV1dJ7ScZgWSOBKi3+qnbcw494pPfh+tKG0xml0+jhbs8wdnsYR5uDUKsLt2cG+009fokac1kDXeIa2sR3EPWWyum/JMcqUeGp1DBW2Uo2tcn52h7bU1mWZ5/y4vkRucc7FHYP2cvscrq4w9FPRUY/M+B8W8n9chWGEjk6cS2ibrGM/pJ67JfV+CrbGCtX43fFWOsKEVIO4bWF8Bp8eO+NkwgmiWpGmLllJjaRxv6BFl9JM/YKNQMliv/DrlIZxhI5JkkTTkkzgUoN+Y0Cb1YK7E9nWUlvsJR4TGFnn5OtAq/mc8y3+1jP5knU2XC+JUeQqDCWKtCW/heKZQhiJaEbeuI3+5itMfFyu0AxtcPFQo6z0yIHx2ecnl9w+OKAw9gyOfMkP3yfJ1JtInpNR6raSuqOheDnvYgM5UrGb3SQarTxVO1is8FOemKR3dEE/5z/xp9//c3p2Wt++fUPCq+O2Y+vkbdESCeekGm0saF08KR1hIzKRrrZjmhEqicovUdcLjDXNESq2shqZIlnY3GOn73k6KzI8c9FLt78znZ+j1x2ixXhIbFAgvlaE5n6QRZaHEwrTYTUAiKfvBe/VE+gro+pRguJj7tZcMdYDH9LMvkda+tbHJ9dcHL+mtVsjtjMHAGLF68tQOSLHmZu9xFVDDDZYCLcIiCy1nXhuq1jTNpJWNpD5NO7BAe8ROILRKfnWMqs8ePBCc/3jkimlolOzeIPTeIUPIx+1I7vEy3fSPVYb3UwVNPJv+V9ES5LTGkQAAAAAElFTkSuQmCC","aspectRatio":1.7699115044247788,"src":"/static/5bb496f1ffa55fce8f7a89258870f8d8/ee604/get_started_with_S3_featureImg.png","srcSet":"/static/5bb496f1ffa55fce8f7a89258870f8d8/69585/get_started_with_S3_featureImg.png 200w,\n/static/5bb496f1ffa55fce8f7a89258870f8d8/497c6/get_started_with_S3_featureImg.png 400w,\n/static/5bb496f1ffa55fce8f7a89258870f8d8/ee604/get_started_with_S3_featureImg.png 800w,\n/static/5bb496f1ffa55fce8f7a89258870f8d8/f3583/get_started_with_S3_featureImg.png 1200w,\n/static/5bb496f1ffa55fce8f7a89258870f8d8/5707d/get_started_with_S3_featureImg.png 1600w,\n/static/5bb496f1ffa55fce8f7a89258870f8d8/eeb1b/get_started_with_S3_featureImg.png 1920w","sizes":"(max-width: 800px) 100vw, 800px"}}}}}},"pageContext":{"slug":"blog/get-started-with-aws-s3"}},"staticQueryHashes":["144257237"]}